{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34673623",
   "metadata": {},
   "source": [
    "# UCI Heart Disease Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "248df9e7",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "2cef4b37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import graphviz\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.exceptions import NotFittedError\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_graphviz\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2565f546",
   "metadata": {},
   "source": [
    "## 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "49c36e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data():\n",
    "    \"\"\"Fetch the Heart Disease dataset from UCI repository.\"\"\"\n",
    "    heart_disease = fetch_ucirepo(id=45)\n",
    "    features = heart_disease.data.features\n",
    "    targets = heart_disease.data.targets\n",
    "\n",
    "    # ƒê·ªïi t√™n c·ªôt target th√†nh \"target\" n·∫øu ch∆∞a ƒë√∫ng\n",
    "    if targets.shape[1] == 1:\n",
    "        targets.columns = [\"target\"]\n",
    "\n",
    "    df = pd.concat([features, targets], axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909f84cf",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "710d5d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"Prepare features and target + create preprocessing pipeline.\"\"\"\n",
    "    numeric_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "    numeric_features = numeric_cols.drop(\"target\") if \"target\" in numeric_cols else numeric_cols\n",
    "    categorical_features = df.select_dtypes(include=[\"object\", \"category\"]).columns\n",
    "\n",
    "    # Added SimpleImputer to handle missing values\n",
    "    numeric_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"mean\")),\n",
    "        (\"scaler\", StandardScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline([\n",
    "        (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "        (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer([\n",
    "        (\"num\", numeric_transformer, numeric_features),\n",
    "        (\"cat\", categorical_transformer, categorical_features)\n",
    "    ])\n",
    "\n",
    "    X = df.drop(\"target\", axis=1)\n",
    "    y = df[\"target\"]\n",
    "    y = np.where(y == 0, 0, 1)\n",
    "    return X, y, preprocessor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df6b792f",
   "metadata": {},
   "source": [
    "## 4. Distribution Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a5a35d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution(y, title=\"Target Distribution\"):\n",
    "    \"\"\"Plot the distribution of the target labels.\"\"\"\n",
    "    # Ensure y is a Pandas Series\n",
    "    if isinstance(y, np.ndarray):\n",
    "        y = pd.Series(y)\n",
    "\n",
    "    counts = y.value_counts().sort_index()\n",
    "    plt.figure(figsize=(5, 3))\n",
    "    plt.bar(counts.index.astype(str), counts.values, color=\"skyblue\")\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Target\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.grid(True, axis='y', linestyle='--', alpha=0.7)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078cda22",
   "metadata": {},
   "source": [
    "## 5. Building the Model Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "88542d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_pipeline(preprocessor, max_depth=None):\n",
    "    \"\"\"Construct a pipeline with preprocessing and decision tree.\"\"\"\n",
    "    return Pipeline([\n",
    "        (\"preprocess\", preprocessor),\n",
    "        (\"classifier\", DecisionTreeClassifier(\n",
    "            max_depth=max_depth, \n",
    "            random_state=42,\n",
    "            criterion='entropy'\n",
    "        ))\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eba19efe",
   "metadata": {},
   "source": [
    "## 6. Training the Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ff881bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(pipeline, X_train, y_train):\n",
    "    \"\"\"Fit the pipeline to training data.\"\"\"\n",
    "    pipeline.fit(X_train, y_train.ravel())  # ravel for compatibility with single-column y\n",
    "    return pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51d32b5",
   "metadata": {},
   "source": [
    "## 7. Evaluating the Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f6d8b874",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(clf, X_test, y_test, title_prefix=\"\"):\n",
    "    \"\"\"Evaluate classifier and visualize results.\"\"\"\n",
    "    y_pred = clf.predict(X_test)\n",
    "    display(Markdown(f\"### {title_prefix} Classification Report\"))\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    display(Markdown(f\"### {title_prefix} Confusion Matrix\"))\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "    disp.plot(cmap=\"Blues\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ba95d8a",
   "metadata": {},
   "source": [
    "## 8. Visualize Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "cb83e1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tree(clf, X_sample, title_prefix=\"\"):\n",
    "    \"\"\"Visualize the decision tree using matplotlib and Graphviz.\"\"\"\n",
    "\n",
    "    display(Markdown(f\"### {title_prefix} Decision Tree Visualization (matplotlib)\"))\n",
    "\n",
    "    # Extract fitted model and preprocessor\n",
    "    model = clf.named_steps[\"classifier\"]\n",
    "    preprocess = clf.named_steps[\"preprocess\"]\n",
    "\n",
    "    # Get the original feature names\n",
    "    num_features = preprocess.transformers_[0][2]\n",
    "    cat_features = preprocess.transformers_[1][2]\n",
    "\n",
    "    # Get the categorical transformer pipeline\n",
    "    cat_transformer = preprocess.named_transformers_[\"cat\"]\n",
    "    ohe = cat_transformer.named_steps[\"encoder\"]\n",
    "\n",
    "    try:\n",
    "        cat_feature_names = ohe.get_feature_names_out(cat_features)\n",
    "    except NotFittedError:\n",
    "        print(\"Creating feature names from sample data...\")\n",
    "        sample_cat_data = X_sample[cat_features].head(10)\n",
    "        cat_feature_names = []\n",
    "        for col in cat_features:\n",
    "            unique_vals = sample_cat_data[col].unique()\n",
    "            for val in unique_vals:\n",
    "                cat_feature_names.append(f\"{col}_{val}\")\n",
    "        cat_feature_names = np.array(cat_feature_names)\n",
    "\n",
    "    # Combine all feature names\n",
    "    all_feature_names = np.concatenate([num_features, cat_feature_names])\n",
    "\n",
    "    # Plot tree using matplotlib\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plot_tree(\n",
    "        model,\n",
    "        feature_names=all_feature_names,\n",
    "        class_names=[\"0\", \"1\"],\n",
    "        filled=True\n",
    "        # max_depth=3\n",
    "    )\n",
    "    plt.title(f\"{title_prefix} Decision Tree (matplotlib)\", fontsize=16, pad=20)\n",
    "    plt.show()\n",
    "\n",
    "    # Graphviz visualization\n",
    "    display(Markdown(f\"### üåê {title_prefix} Decision Tree (Graphviz)\"))\n",
    "\n",
    "    dot_data = export_graphviz(\n",
    "        model,\n",
    "        out_file=None,\n",
    "        feature_names=all_feature_names,\n",
    "        class_names=[\"0\", \"1\"],\n",
    "        filled=True,\n",
    "        rounded=True,\n",
    "        special_characters=True,\n",
    "        fontname=\"Arial\"\n",
    "        # max_depth=3\n",
    "    )\n",
    "    graph = graphviz.Source(dot_data)\n",
    "    display(graph)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1f8c732",
   "metadata": {},
   "source": [
    "## 9. Run Experiments for Different Test Sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "42112b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_experiments(df, test_ratios=[0.1, 0.2, 0.4, 0.6]):\n",
    "    \"\"\"Train and evaluate the model for different test sizes.\"\"\"\n",
    "    X, y, preprocessor = preprocess_data(df)\n",
    "    accuracies = []\n",
    "    depths = []\n",
    "    models = []\n",
    "\n",
    "    for ratio in test_ratios:\n",
    "        display(Markdown(f\"## Test Size: {ratio}\"))\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=ratio, stratify=y, random_state=42\n",
    "        )\n",
    "\n",
    "        # Plot class distribution to validate stratification\n",
    "        plot_distribution(y_train, f\"Train Set Distribution ({int((1-ratio)*100)}%)\")\n",
    "        plot_distribution(y_test, f\"Test Set Distribution ({int(ratio*100)}%)\")\n",
    "\n",
    "        pipeline = build_pipeline(preprocessor)\n",
    "        clf = train_model(pipeline, X_train, y_train)\n",
    "        acc = clf.score(X_test, y_test)\n",
    "        depth = clf.named_steps[\"classifier\"].get_depth()\n",
    "\n",
    "        accuracies.append(acc)\n",
    "        depths.append(depth)\n",
    "        models.append(clf)\n",
    "\n",
    "        evaluate_model(clf, X_test, y_test, title_prefix=f\"Test Size {ratio}\")\n",
    "        \n",
    "        # Fix: Use X_train instead of undefined X_sample\n",
    "        visualize_tree(clf, X_train, title_prefix=f\"Test Size {ratio}\")\n",
    "\n",
    "    # Plot accuracy and depth vs test size\n",
    "    test_percent = [int(r*100) for r in test_ratios]\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(test_percent, accuracies, marker='o', color='green')\n",
    "    plt.title(\"Accuracy vs Test Size\")\n",
    "    plt.xlabel(\"Test Size (%)\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.grid(True)\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(test_percent, depths, marker='s', color='orange')\n",
    "    plt.title(\"Tree Depth vs Test Size\")\n",
    "    plt.xlabel(\"Test Size (%)\")\n",
    "    plt.ylabel(\"Tree Depth\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return models, accuracies, depths"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bb89cb2",
   "metadata": {},
   "source": [
    "## 10. Max Depth Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b2f99ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def max_depth_experiment(df, test_size=0.2, depths=[None, 2, 3, 4, 5, 6, 7]):\n",
    "    \"\"\"Experiment with different max_depth values for decision tree.\"\"\"\n",
    "    display(Markdown(f\"## Max Depth Experiment (Test Size = {int(test_size*100)}%)\"))\n",
    "    \n",
    "    X, y, preprocessor = preprocess_data(df)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=42\n",
    "    )\n",
    "\n",
    "    accuracies = []\n",
    "    models = []\n",
    "    \n",
    "    for d in depths:\n",
    "        display(Markdown(f\"### Max Depth = {d if d is not None else 'None'}\"))\n",
    "        \n",
    "        # Build pipeline with specific max_depth\n",
    "        pipeline = build_pipeline(preprocessor, max_depth=d)\n",
    "        clf = train_model(pipeline, X_train, y_train)\n",
    "        \n",
    "        # Evaluate model\n",
    "        evaluate_model(clf, X_test, y_test, title_prefix=f\"Max Depth {d}\")\n",
    "        \n",
    "        # Visualize tree\n",
    "        visualize_tree(clf, X_train, title_prefix=f\"Max Depth {d}\")\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        acc = clf.score(X_test, y_test)\n",
    "        accuracies.append(acc)\n",
    "        models.append(clf)\n",
    "        \n",
    "        print(f\"Max Depth = {d if d is not None else 'None'} ‚Üí Accuracy = {acc:.4f}\")\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "    # Plot accuracy vs max_depth\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    depth_labels = [str(d) if d is not None else 'None' for d in depths]\n",
    "    plt.plot(range(len(depths)), accuracies, marker='o', linewidth=2, markersize=8)\n",
    "    plt.xticks(range(len(depths)), depth_labels)\n",
    "    plt.title(\"Accuracy vs Max Depth\", fontsize=14)\n",
    "    plt.xlabel(\"Max Depth\", fontsize=12)\n",
    "    plt.ylabel(\"Accuracy\", fontsize=12)\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Create results table\n",
    "    results_df = pd.DataFrame({\n",
    "        'max_depth': depth_labels,\n",
    "        'accuracy': [f\"{acc:.4f}\" for acc in accuracies]\n",
    "    })\n",
    "    \n",
    "    display(Markdown(\"### Results Summary\"))\n",
    "    display(results_df)\n",
    "    \n",
    "    return models, accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9494d0a",
   "metadata": {},
   "source": [
    "## 11. Main Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09b2a816",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = load_data()\n",
    "run_experiments(df)\n",
    "\n",
    "# Optional: Uncomment to try max_depth analysis\n",
    "# max_depth_experiment(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
