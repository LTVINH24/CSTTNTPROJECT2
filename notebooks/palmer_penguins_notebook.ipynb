{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd23b4cd",
   "metadata": {},
   "source": [
    "# PALMER PENGUINS NOTEBOOK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64077fb",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cfca93eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\2024-2025\\CSTTNT\\Project3\\CSTTNTPROJECT2\\.venv\\Lib\\site-packages\\palmerpenguins\\penguins.py:2: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, ConfusionMatrixDisplay\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn import tree\n",
    "from graphviz import Source\n",
    "from IPython.display import display\n",
    "# Dataset loaders\n",
    "from palmerpenguins import load_penguins "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3de1f6c",
   "metadata": {},
   "source": [
    "## 2. Load Dataset + Basic Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cfe716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after removing missing species:\n",
      "X shape: (344, 7)\n",
      "y shape: (344,)\n"
     ]
    }
   ],
   "source": [
    "penguins =load_penguins()\n",
    "# Remove any rows where the 'species' value is missing (NaN)\n",
    "penguins_cleaned = penguins.dropna(subset=['species']).copy()\n",
    "# Separate the dataset into features (X) and target labels (y)\n",
    "X = penguins_cleaned.drop(columns=['species'])\n",
    "y = penguins_cleaned['species']\n",
    "print(\"Shape after removing missing species:\")\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad935485",
   "metadata": {},
   "source": [
    "## 3. Full Preprocessing with Imputer + OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05908e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_features(X):\n",
    "    # Identify the names of categorical and numerical columns in the dataset\n",
    "    categorical_columns = X.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "    numerical_columns = X.select_dtypes(include=['number']).columns.tolist()\n",
    "     # For numerical columns: replace missing values with the mean of each column\n",
    "     # For categorical columns: one-hot encode and handle unknown categories\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', SimpleImputer(strategy='mean'), numerical_columns),\n",
    "            ('cat', OneHotEncoder(handle_unknown='ignore',sparse_output=False), categorical_columns)\n",
    "        ],\n",
    "        remainder='passthrough'\n",
    "    )\n",
    "    X_processed = preprocessor.fit_transform(X)\n",
    "    feature_names = numerical_columns.copy()\n",
    "    if categorical_columns:\n",
    "        cat_encoded_names= preprocessor.named_transformers_['cat'].get_feature_names_out(categorical_columns)\n",
    "        feature_names.extend(cat_encoded_names)\n",
    "    return pd.DataFrame(X_processed, columns=feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d08d8c",
   "metadata": {},
   "source": [
    "## 4. Data Splitting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91591013",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train/test sets with stratified sampling to maintain class distribution\n",
    "def split_dataset(X,y,test_size):\n",
    "    return train_test_split(X,y,test_size=test_size,stratify=y,shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c43ad45",
   "metadata": {},
   "source": [
    "## 5. Train Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d385b34e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a decision tree classifier with entropy criterion\n",
    "def train_decision_tree(X_train, y_train, max_depth=None):\n",
    "    clf = DecisionTreeClassifier(criterion='entropy',max_depth=max_depth, random_state=42)\n",
    "    clf.fit(X_train, y_train)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baa28b24",
   "metadata": {},
   "source": [
    "## 6. Visualize Label Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c8edae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to visualize the label distribution\n",
    "def plot_distribution(y, title):\n",
    "    y = pd.Series(y.ravel())  # Ensure 1D\n",
    "    sns.countplot(x=y)\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Species\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d027a0d0",
   "metadata": {},
   "source": [
    "## 7. Visualize Decision Trees with Graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad2568f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export the trained decision tree to DOT format (Graphviz format)\n",
    "def draw_decision_tree(tree_model, feature_names,class_names):\n",
    "    dot_data = tree.export_graphviz(\n",
    "        tree_model,\n",
    "        out_file=None, \n",
    "        feature_names=feature_names,  \n",
    "        class_names=class_names,  \n",
    "        filled=True,\n",
    "        rounded=True,  \n",
    "        special_characters=True)  \n",
    "    graph = Source(dot_data)\n",
    "    display(graph)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40607dff",
   "metadata": {},
   "source": [
    "## 8. Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5f2164c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_classification_report(y_test,y_pred,target_names):\n",
    "    print(classification_report(y_true=y_test, y_pred=y_pred, target_names=target_names))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db7b5caf",
   "metadata": {},
   "source": [
    "## 9. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "14f6e228",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(y_test, y_pred,target_names,labels,depth,test_size):\n",
    "    cm = confusion_matrix(y_test, y_pred, labels=labels)\n",
    "    display = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=target_names)\n",
    "    figure,axes = plt.subplots(figsize=(8, 8))\n",
    "    display.plot(ax=axes, cmap=plt.cm.Blues, values_format='d')\n",
    "    plt.title(f\"Confusion Matrix (Depth={depth}, {100 - int(test_size * 100)}/{int(test_size * 100)} Split)\")\n",
    "    plt.grid(False)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c852342f",
   "metadata": {},
   "source": [
    "## 10. Max Depth - Accurary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374b7c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print table of relationship between max_depth and accuracy\n",
    "def print_max_depth_accuracy(max_depths, accuracies):\n",
    "    df = pd.DataFrame([accuracies],columns=[str(v) if v is not None else 'None' for v in max_depths],index=['Accuracy'])\n",
    "    df.columns.name = 'max_depth'\n",
    "    print(df)\n",
    "\n",
    "# Draw a chart of accuracy by max_depth\n",
    "def max_depth_accuracy_chart(max_depths,accuracies):\n",
    "    plot_x = [-1 if v is None else v for v in max_depths]\n",
    "    labels_x =[str(v) if v is not None else 'None' for v in max_depths]\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(plot_x,accuracies,'o-', color='blue')\n",
    "    plt.title('Decision Tree Accuracy by Maximum Depth')\n",
    "    plt.xlabel('Max Depth')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xticks(plot_x, labels_x)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d781f522",
   "metadata": {},
   "source": [
    "## 11. Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056fbe69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(): \n",
    "    split_ratios =[0.6, 0.4, 0.2, 0.1, 0.2]\n",
    "    X_processed = preprocess_features(X)\n",
    "    feature_names = X_processed.columns.tolist()\n",
    "    # Extract feature names from processed dataset for visualization\n",
    "    target_names = [\"Adelie\", \"Chinstrap\", \"Gentoo\"]\n",
    "    class_names = [label for label in target_names if label in y.unique()]\n",
    "    # Filter to get only class names that actually exist in the dataset\n",
    "    for i in range(0,4):\n",
    "        print(f\"{i}: Train/Test = {100 - int(split_ratios[i] * 100)}/{int(split_ratios[i] * 100)}\")\n",
    "    print(\"4: Max Depth Accuracy Analysis\")\n",
    "    # Menu for user to choose split ratio\n",
    "    choose = int(input(\"Choose a split ratio (0-4): \"))\n",
    "    X_train, X_test, y_train, y_test = split_dataset(X_processed, y, split_ratios[choose])\n",
    "    match choose:\n",
    "        case 0 | 1 | 2 | 3: #Standard decision tree analysis with visualization\n",
    "            clf = train_decision_tree(X_train, y_train, max_depth=None)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            plot_distribution(y, \"Original Dataset Distribution\")\n",
    "            plot_distribution(y_train, \"Training Set Distribution\")\n",
    "            plot_distribution(y_test, \"Test Set Distribution\")\n",
    "            draw_decision_tree(clf, feature_names, class_names)\n",
    "            print_classification_report(y_test, y_pred,target_names)\n",
    "            plot_confusion_matrix(y_test,y_pred,target_names,labels=class_names,depth=None, test_size=split_ratios[choose])\n",
    "        case 4: #  Max depth analysis - compare different tree depths\n",
    "            max_depths= [None,2,3,4,5,6,7]\n",
    "            accuracies = []\n",
    "            for max_depth in max_depths:\n",
    "                clf = train_decision_tree(X_train,y_train,max_depth)\n",
    "                y_pred = clf.predict(X_test)\n",
    "                accuracy = accuracy_score(y_test, y_pred)\n",
    "                accuracies.append(accuracy)\n",
    "            print(\"\\n\\n\")\n",
    "            print_max_depth_accuracy(max_depths,accuracies)\n",
    "            max_depth_accuracy_chart(max_depths, accuracies)\n",
    "        case _:\n",
    "            print(\"Please choose a valid option (0-3).\")\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
